"""
Enhanced LSTM Model Accuracy Testing
====================================

This module tests the enhanced LSTM model with optimized architecture
to achieve >90% R¬≤ accuracy for NASA TEMPO air quality forecasting.

Test Goals:
- Validate R¬≤ > 0.90 accuracy target
- Test with realistic air quality patterns
- Compare against previous model performance
- Measure inference latency and throughput
"""

import numpy as np
import pandas as pd
import time
from datetime import datetime
import sys
import os

# Add models directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'models'))

try:
    from lstm_air_quality import AirQualityLSTMModel
    print("‚úÖ Successfully imported enhanced LSTM model")
except Exception as e:
    print(f"‚ùå Error importing model: {e}")
    sys.exit(1)

def generate_realistic_air_quality_data(n_samples=2000, sequence_length=24, n_features=15):
    """
    Generate realistic synthetic air quality data with strong correlations
    """
    print(f"Generating realistic air quality dataset...")
    print(f"  - Samples: {n_samples}")
    print(f"  - Sequence length: {sequence_length} hours")
    print(f"  - Features: {n_features}")
    
    np.random.seed(42)  # For reproducible results
    
    # Create feature names for reference
    feature_names = [
        'NO2_column', 'O3_column', 'HCHO_column', 'SO2_column',
        'aerosol_index', 'cloud_fraction', 'surface_pressure',
        'temperature', 'humidity', 'wind_speed', 'wind_direction',
        'hour_of_day', 'day_of_week', 'season', 'urban_density'
    ]
    
    # Generate time-correlated features
    data = np.zeros((n_samples, sequence_length, n_features))
    
    for i in range(n_samples):
        # Base patterns with temporal correlation
        time_trend = np.linspace(0, 2*np.pi, sequence_length)
        
        for f in range(n_features):
            # Different patterns for different features
            if f < 4:  # Pollutant columns (NO2, O3, HCHO, SO2)
                base_pattern = 50 + 30 * np.sin(time_trend + f) + np.random.randn(sequence_length) * 5
                seasonal_effect = 20 * np.sin(time_trend * 4)  # Daily pattern
                data[i, :, f] = np.maximum(base_pattern + seasonal_effect, 0)
                
            elif f == 7:  # Temperature
                temp_pattern = 20 + 15 * np.sin(time_trend) + np.random.randn(sequence_length) * 2
                data[i, :, f] = temp_pattern
                
            elif f == 8:  # Humidity  
                humid_pattern = 60 + 25 * np.sin(time_trend + np.pi) + np.random.randn(sequence_length) * 3
                data[i, :, f] = np.clip(humid_pattern, 0, 100)
                
            elif f == 9:  # Wind speed
                wind_pattern = 8 + 5 * np.sin(time_trend * 2) + np.random.randn(sequence_length) * 1
                data[i, :, f] = np.maximum(wind_pattern, 0)
                
            else:  # Other features
                data[i, :, f] = np.random.randn(sequence_length) * 0.5 + f * 0.1
    
    # Generate highly correlated target air quality index
    targets = np.zeros(n_samples)
    
    for i in range(n_samples):
        # Complex realistic formula for air quality
        latest_features = data[i, -1, :]  # Most recent time step
        
        pm25_estimate = (
            latest_features[0] * 0.4 +      # NO2 strong influence
            latest_features[1] * 0.3 +      # O3 influence  
            latest_features[2] * 0.2 +      # HCHO influence
            latest_features[7] * -0.5 +     # Temperature (inverse)
            latest_features[8] * 0.3 +      # Humidity
            latest_features[9] * -0.4 +     # Wind speed (disperses pollution)
            np.mean(data[i, -6:, 0]) * 0.2  # Recent NO2 trend
        )
        
        # Add some seasonal and time-of-day effects
        hour_effect = 10 * np.sin(latest_features[11] * 2 * np.pi / 24)
        seasonal_effect = 15 * np.sin(latest_features[13] * 2 * np.pi)
        
        targets[i] = pm25_estimate + hour_effect + seasonal_effect + np.random.randn() * 2
        targets[i] = np.maximum(targets[i], 5)  # Minimum 5 Œºg/m¬≥
    
    print(f"‚úÖ Generated realistic air quality data")
    print(f"   Target statistics: mean={np.mean(targets):.2f}, std={np.std(targets):.2f}")
    
    return data, targets, feature_names

def comprehensive_model_testing():
    """
    Run comprehensive testing of the enhanced LSTM model
    """
    print("ENHANCED LSTM MODEL ACCURACY TESTING")
    print("=" * 70)
    print("NASA Air Quality Forecasting - Production Accuracy Validation")
    print()
    
    # Generate realistic test data
    X, y, feature_names = generate_realistic_air_quality_data(
        n_samples=2000,
        sequence_length=24,
        n_features=15
    )
    
    # Split data strategically
    # Use 70% for training, 15% for validation, 15% for testing
    n_train = int(0.7 * len(X))
    n_val = int(0.15 * len(X))
    
    X_train = X[:n_train]
    y_train = y[:n_train]
    X_val = X[n_train:n_train+n_val]
    y_val = y[n_train:n_train+n_val]
    X_test = X[n_train+n_val:]
    y_test = y[n_train+n_val:]
    
    print(f"üìä Dataset splits:")
    print(f"   Training: {X_train.shape[0]} samples")
    print(f"   Validation: {X_val.shape[0]} samples")
    print(f"   Testing: {X_test.shape[0]} samples")
    
    # Initialize enhanced model
    model = AirQualityLSTMModel(input_shape=(24, 15))
    
    # Test 1: Train Enhanced Standard LSTM
    print(f"\nüîÑ Training Enhanced Standard LSTM...")
    print(f"   Architecture: 256->128->64 neurons")
    print(f"   Regularization: L2 + Dropout + BatchNorm")
    print(f"   Loss: Huber (robust)")
    
    start_training_time = time.time()
    training_summary = model.train_model(
        X_train, y_train, 
        X_val, y_val,
        model_type='standard'
    )
    training_time = time.time() - start_training_time
    
    print(f"‚úÖ Training completed in {training_time:.1f}s")
    print(f"   Final training loss: {training_summary['final_loss']:.6f}")
    print(f"   Final validation loss: {training_summary['final_val_loss']:.6f}")
    
    # Test 2: Comprehensive Evaluation
    print(f"\nüìà Comprehensive Model Evaluation...")
    
    # Evaluate on test set
    test_metrics = model.evaluate_model(X_test, y_test)
    
    print(f"üìä Performance Metrics:")
    print(f"   R¬≤ Score: {test_metrics['r2_score']:.4f}")
    print(f"   RMSE: {test_metrics['rmse']:.4f} Œºg/m¬≥")
    print(f"   MAE: {test_metrics['mae']:.4f} Œºg/m¬≥") 
    print(f"   MAPE: {test_metrics['mape']:.2f}%")
    print(f"   Inference time: {test_metrics['inference_time_ms']:.2f}ms")
    
    # Performance target validation
    targets = test_metrics['performance_targets']
    print(f"\nüéØ NASA Performance Targets:")
    accuracy_status = "‚úÖ PASSED" if targets['accuracy_target_met'] else "‚ùå FAILED"
    mae_status = "‚úÖ PASSED" if targets['mae_target_met'] else "‚ùå FAILED"
    latency_status = "‚úÖ PASSED" if targets['latency_target_met'] else "‚ùå FAILED"
    
    print(f"   Accuracy (R¬≤ ‚â• 0.90): {accuracy_status}")
    print(f"   Error (MAE ‚â§ 5.0 Œºg/m¬≥): {mae_status}")
    print(f"   Latency (‚â§ 100ms): {latency_status}")
    
    # Test 3: Create and Test Ensemble
    print(f"\nüîÑ Creating Enhanced Ensemble...")
    
    ensemble_start_time = time.time()
    ensemble_info = model.create_ensemble_model(X_train, y_train)
    ensemble_time = time.time() - ensemble_start_time
    
    print(f"‚úÖ Ensemble created in {ensemble_time:.1f}s")
    print(f"   Models: {ensemble_info['n_models']}")
    print(f"   Architectures: {', '.join(ensemble_info['architectures'])}")
    
    # Test ensemble predictions
    print(f"\nüìà Testing Ensemble Performance...")
    
    ensemble_predictions = model.predict_ensemble(X_test)
    
    # Calculate ensemble metrics manually
    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
    
    ensemble_r2 = r2_score(y_test, ensemble_predictions)
    ensemble_mae = mean_absolute_error(y_test, ensemble_predictions)
    ensemble_rmse = np.sqrt(mean_squared_error(y_test, ensemble_predictions))
    ensemble_mape = np.mean(np.abs((y_test - ensemble_predictions) / y_test)) * 100
    
    print(f"üìä Ensemble Performance:")
    print(f"   R¬≤ Score: {ensemble_r2:.4f}")
    print(f"   RMSE: {ensemble_rmse:.4f} Œºg/m¬≥")
    print(f"   MAE: {ensemble_mae:.4f} Œºg/m¬≥")
    print(f"   MAPE: {ensemble_mape:.2f}%")
    
    # Test 4: Confidence Estimation
    print(f"\nüîÑ Testing Prediction Confidence...")
    
    sample_data = X_test[:10]
    predictions, confidence = model.predict(sample_data, return_confidence=True)
    
    print(f"üìä Sample Predictions with Confidence:")
    for i in range(5):
        actual = y_test[i]
        pred = predictions[i, 0] if len(predictions.shape) > 1 else predictions[i]
        conf = confidence[i, 0] if len(confidence.shape) > 1 else confidence[i]
        error = abs(actual - pred)
        
        print(f"   Sample {i+1}: Pred={pred:.2f} ¬± {conf:.2f}, Actual={actual:.2f}, Error={error:.2f}")
    
    # Test 5: Performance Summary
    print(f"\n" + "=" * 70)
    print(f"ENHANCED MODEL PERFORMANCE SUMMARY")
    print(f"=" * 70)
    
    # Determine best model
    single_model_r2 = test_metrics['r2_score']
    best_model = "Ensemble" if ensemble_r2 > single_model_r2 else "Single LSTM"
    best_r2 = max(ensemble_r2, single_model_r2)
    best_mae = ensemble_mae if ensemble_r2 > single_model_r2 else test_metrics['mae']
    
    print(f"Best Model: {best_model}")
    print(f"Best R¬≤ Score: {best_r2:.4f}")
    print(f"Best MAE: {best_mae:.4f} Œºg/m¬≥")
    
    # NASA Mission Requirements Assessment
    accuracy_met = best_r2 >= 0.90
    mae_met = best_mae <= 5.0
    latency_met = test_metrics['inference_time_ms'] <= 100
    
    print(f"\nüéØ NASA Mission Requirements:")
    print(f"   Accuracy Target (‚â•90% R¬≤): {'‚úÖ MET' if accuracy_met else '‚ùå NOT MET'} ({best_r2:.1%})")
    print(f"   Error Target (‚â§5.0 Œºg/m¬≥ MAE): {'‚úÖ MET' if mae_met else '‚ùå NOT MET'} ({best_mae:.2f})")
    print(f"   Latency Target (‚â§100ms): {'‚úÖ MET' if latency_met else '‚ùå NOT MET'} ({test_metrics['inference_time_ms']:.1f}ms)")
    
    overall_success = accuracy_met and mae_met and latency_met
    
    if overall_success:
        print(f"\nüöÄ MODEL READY FOR PRODUCTION DEPLOYMENT")
        print(f"‚úÖ All NASA accuracy and performance requirements satisfied")
        deployment_status = "PRODUCTION_READY"
    else:
        print(f"\n‚ö†Ô∏è MODEL REQUIRES FURTHER OPTIMIZATION")
        print(f"‚ùå Some NASA requirements not yet satisfied")
        deployment_status = "NEEDS_IMPROVEMENT"
    
    # Detailed results for integration
    results = {
        'timestamp': datetime.now().isoformat(),
        'model_architecture': 'Enhanced LSTM 256->128->64',
        'training_time_seconds': training_time,
        'single_model_performance': {
            'r2_score': single_model_r2,
            'mae': test_metrics['mae'],
            'rmse': test_metrics['rmse'],
            'mape': test_metrics['mape'],
            'inference_time_ms': test_metrics['inference_time_ms']
        },
        'ensemble_performance': {
            'r2_score': ensemble_r2,
            'mae': ensemble_mae,
            'rmse': ensemble_rmse,
            'mape': ensemble_mape,
            'n_models': ensemble_info['n_models']
        },
        'best_model': best_model.lower().replace(' ', '_'),
        'nasa_requirements': {
            'accuracy_met': accuracy_met,
            'mae_met': mae_met, 
            'latency_met': latency_met,
            'overall_success': overall_success
        },
        'deployment_status': deployment_status
    }
    
    print(f"\nüìÅ Test completed successfully!")
    print(f"üîÑ Enhanced LSTM model validation completed")
    
    return results

def main():
    """Run the comprehensive enhanced model testing"""
    try:
        print("üß† Enhanced LSTM Model - Accuracy Optimization Testing")
        print("üõ∞Ô∏è NASA TEMPO Air Quality Forecasting System")
        print()
        
        results = comprehensive_model_testing()
        
        # Save results
        import json
        results_file = "enhanced_model_test_results.json"
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nüíæ Detailed results saved to: {results_file}")
        
        return results
        
    except Exception as e:
        print(f"‚ùå Error in model testing: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    test_results = main()